(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{382:function(a,e,t){"use strict";t.r(e);var o=t(19),r=Object(o.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"hadoop生态系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop生态系统"}},[a._v("#")]),a._v(" Hadoop生态系统")]),a._v(" "),t("p",[a._v("当今的Hadoop已经成长为一个庞大的体系，只要有和海量数据相关的领域。都有Hadoop的身影。\n"),t("strong",[a._v("Hadoop生态系统图谱")]),a._v(" "),t("center",[t("img",{attrs:{src:"/img/BigData/Hadoop/006tNc79ly1fz7nez9hccj30fs0b7tg1.jpg"}}),a._v(" "),t("br"),a._v(" "),t("div",{staticClass:"imgtext"},[a._v("Hadoop生态系统图谱")]),a._v(" "),t("br")]),a._v("\n大家知道，Hadoop的两大核心就是HDFS和MapReduce，而整个Hadoop的体系结构主要是通过HDFS的分布式存储作为底层数据支持的。并且会通过MapReduce来进行计算分析。\n"),t("strong",[a._v("Hadoop1.x的核心：")])],1),a._v(" "),t("ol",[t("li",[a._v("Hadoop Common")]),a._v(" "),t("li",[a._v("Hadoop Distributed File System（HDFS）")]),a._v(" "),t("li",[a._v("Hadoop MapReduce")])]),a._v(" "),t("p",[t("strong",[a._v("Hadoop2.x的核心：")])]),a._v(" "),t("ol",[t("li",[a._v("Hadoop Common")]),a._v(" "),t("li",[a._v("Hadoop Distributed File System（HDFS）")]),a._v(" "),t("li",[a._v("Hadoop MapReduce")]),a._v(" "),t("li",[a._v("Hadoop YARN")])]),a._v(" "),t("p",[t("strong",[a._v("Hadoop1.x 生态系统图")]),a._v(" "),t("img",{attrs:{src:"/img/BigData/Hadoop/006tNc79ly1fz7nfabg1ej30ks0ag437.jpg",alt:"image-20190115224213255"}}),a._v(" "),t("strong",[a._v("Hadoop2.x 生态系统图")]),a._v(" "),t("img",{attrs:{src:"/img/BigData/Hadoop/006tNc79ly1fz7nfkw99wj30rh0ew7f7.jpg",alt:"image-20190115224223572"}})]),a._v(" "),t("h2",{attrs:{id:"hadoop1-x-的各项目介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop1-x-的各项目介绍"}},[a._v("#")]),a._v(" Hadoop1.x 的各项目介绍")]),a._v(" "),t("h3",{attrs:{id:"_1-hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-hdfs"}},[a._v("#")]),a._v(" 1. HDFS")]),a._v(" "),t("p",[a._v("分布式文件系统，将一个文件分成多个块，分别存储(拷贝)到不同的节点上.它是Hadoop体系中"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("数据存储管理")]),a._v("的基础。它是一个高度容错的系统，能检测和应对硬件故障，用于在低成本的通用硬件上运行。HDFS简化了文件的一致性模型，通过流式数据访问，提供高吞吐量应用程序数据访问功能，适合带有大型数据集的应用程序。")],1),a._v(" "),t("h3",{attrs:{id:"_2-mapreduce"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-mapreduce"}},[a._v("#")]),a._v(" 2. MapReduce")]),a._v(" "),t("p",[a._v("分布式计算框架，它是一种分布式计算处理模型和执行环境，用于进行"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("大数据量的计算")]),a._v("。共包括Map和Reduce部分。其中Map接受一个键值对（key-value），产生一组中间键值对。MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。Reduce函数：接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。")],1),a._v(" "),t("h3",{attrs:{id:"_3-hive"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-hive"}},[a._v("#")]),a._v(" 3. "),t("a",{attrs:{href:"http://hive.apache.org/",title:"Data warehouse infrastructure using the Apache Hadoop Database",target:"_blank",rel:"noopener noreferrer"}},[a._v("Hive"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("基于Hadoop的"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("数据仓库工具")]),a._v("，可以将结构化的数据文件映射为一张数据库表，并提供类似SQL一样的查询语言HiveQL来管理这些数据。Hive定义了一种类似SQL的查询语言(HQL),"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("将SQL转化为MapReduce任务在Hadoop上执行")]),a._v("。通常用于离线分析。")],1),a._v(" "),t("h3",{attrs:{id:"_4-pig"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-pig"}},[a._v("#")]),a._v(" 4. "),t("a",{attrs:{href:"http://pig.apache.org/",title:"Platform for analyzing large data sets",target:"_blank",rel:"noopener noreferrer"}},[a._v("Pig"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("Pig是一个基于Hadoop的大数据分析平台，它提供了一个叫PigLatin的高级语言来表达大数据分析程序，"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("将脚本转换为MapReduce任务在Hadoop上执行")]),a._v("。通常用于进行离线分析。")],1),a._v(" "),t("h3",{attrs:{id:"_5-mahout"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-mahout"}},[a._v("#")]),a._v(" 5. "),t("a",{attrs:{href:"http://mahout.apache.org/",title:"Scalable machine learning library",target:"_blank",rel:"noopener noreferrer"}},[a._v("Mahout"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("数据挖掘算法库，Mahout起源于2008年，最初是Apache Lucent的子项目，它在极短的时间内取得了长足的发展，现在是Apache的顶级项目。Mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout现在已经包含了聚类、分类、推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。除了算法，Mahout还包含数据的输入/输出工具、与其他存储系统（如数据库、MongoDB 或Cassandra）集成等数据挖掘支持架构。")]),a._v(" "),t("h3",{attrs:{id:"_6-zookeeper"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-zookeeper"}},[a._v("#")]),a._v(" 6. "),t("a",{attrs:{href:"http://zookeeper.apache.org/",title:"Centralized service for maintaining configuration information",target:"_blank",rel:"noopener noreferrer"}},[a._v("ZooKeeper"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("分布式协作服务，是一个针对大型分布式系统的可靠协调系统，提供包括配置维护，名字服务，分布式同步和组服务等功能。"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("Hadoop的管理就是用的ZooKeeper")])],1),a._v(" "),t("h3",{attrs:{id:"_7-hbase"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-hbase"}},[a._v("#")]),a._v(" 7. "),t("a",{attrs:{href:"http://hbase.apache.org/",title:"Apache Hadoop Database",target:"_blank",rel:"noopener noreferrer"}},[a._v("HBase"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("HBase是一个"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("分布式列存数据库")]),a._v("，它基于Hadoop之上提供了类似BigTable的功能。HBase是一个针对结构化数据的"),t("strong",[a._v("可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库")]),a._v("。和传统关系数据库不同，HBase采用了BigTable的数据模型：增强的稀疏排序映射表（Key/Value），其中，键由行关键字、列关键字和时间戳构成。HBase提供了对大规模数据的随机、实时读写访问，同时，HBase中保存的数据可以使用MapReduce来处理，它将数据存储和并行计算完美地结合在一起。")],1),a._v(" "),t("h3",{attrs:{id:"_8-sqoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-sqoop"}},[a._v("#")]),a._v(" 8. "),t("a",{attrs:{href:"http://sqoop.apache.org/",title:"Bulk Data Transfer for Apache Hadoop and Structured Datastores",target:"_blank",rel:"noopener noreferrer"}},[a._v("Sqoop"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("数据同步工具，SQL-to-Hadoop的缩写。Sqoop是一个Hadoop和关系型数据库之间的数据转移工具。"),t("font",{staticStyle:{color:"red","font-weight":"bold"}},[a._v("可将关系型数据库中的数据导入到Hadoop的HDFS中，也可将HDFS中的数据导进到关系型数据库中")]),a._v("主要用于传统数据库和Hadoop之前传输数据。数据的导入和导出本质上是Mapreduce程序，充分利用了MR的并行化和容错性。")],1),a._v(" "),t("h3",{attrs:{id:"_9-flume"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-flume"}},[a._v("#")]),a._v(" 9. "),t("a",{attrs:{href:"http://flume.apache.org/",title:"A reliable service for efficiently collecting, aggregating, and moving large amounts of log data",target:"_blank",rel:"noopener noreferrer"}},[a._v("Flume"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("日志收集工具，Cloudera开源的日志收集系统，具有分布式、高可靠、高容错、易于定制和扩展的特点。它将数据从产生、传输、处理并最终写入目标的路径的过程抽象为数据流，在具体的数据流中，数据源支持在Flume中定制数据发送方，从而支持收集各种不同协议数据。同时，Flume数据流提供对日志数据进行简单处理的能力，如过滤、格式转换等。此外，Flume还具有能够将日志写往各种数据目标（可定制）的能力。总的来说，Flume是一个可扩展、适合复杂环境的海量日志收集系统。")]),a._v(" "),t("h3",{attrs:{id:"_10-ambari"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-ambari"}},[a._v("#")]),a._v(" 10. "),t("a",{attrs:{href:"http://ambari.apache.org/",title:"Hadoop cluster management",target:"_blank",rel:"noopener noreferrer"}},[a._v("Ambari"),t("OutboundLink")],1)]),a._v(" "),t("p",[a._v("是一个对Hadoop集群进行监控和管理的基于Web的系统。目前已经支持HDFS，MapReduce，Hive，HCatalog，HBase，ZooKeeper，Oozie，Pig和Sqoop等组件。")])])}),[],!1,null,null,null);e.default=r.exports}}]);